{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance a pole on a cart, move the cart left or right to maintain balance\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# 2 actions: move cart left or move cart rigth\n",
    "print(env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)\n"
     ]
    }
   ],
   "source": [
    "# 4 means: position of cart, velocity of cart, angle of pole, rotation rate of pole\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "# lower bounds of the 4 values that make up the observation space\n",
    "print(env.observation_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "# upper bounds of the 4 values that make up the observation space\n",
    "print(env.observation_space.high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretize the state space so we can apply Q-learning to a bounded space\n",
    "# first variable represents position of the cart\n",
    "# cart position: 2 states, left or right - reducing this to 1 means that we're ignoring this variable in our state space\n",
    "# second varible refers to the cart velocity\n",
    "# cart velocity: reduces to 1, we ignore this state as well\n",
    "# reduced our state space along 2 dimensions - makes our learning much faster as our Q-table size is smaller\n",
    "# other two variable represent bucketize the pole position with respect to the vertical and angular velocity\n",
    "# 6 buckets to represent the vertical velocity\n",
    "# 3 buckets to represent the angular velocity\n",
    "NUM_BUCKETS = (1, 1, 6, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cart actions - move left or move right\n",
    "NUM_ACTIONS = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_BOUNDS = list(zip(env.observation_space.low, env.observation_space.high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cart velocity bounds\n",
    "STATE_BOUNDS[1] = [-0.5, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pole angular velocity bounds\n",
    "STATE_BOUNDS[3] = [-math.radians(50), math.radians(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-4.8, 4.8), [-0.5, 0.5], (-0.41887903, 0.41887903), [-0.8726646259971648, 0.8726646259971648]]\n"
     ]
    }
   ],
   "source": [
    "print(STATE_BOUNDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_states * num_actions = (1*1*6*3) * 2\n",
    "q_table = np.zeros(NUM_BUCKETS + (NUM_ACTIONS,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 6, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "print(q_table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[0. 0.]\n",
      "    [0. 0.]\n",
      "    [0. 0.]]\n",
      "\n",
      "   [[0. 0.]\n",
      "    [0. 0.]\n",
      "    [0. 0.]]\n",
      "\n",
      "   [[0. 0.]\n",
      "    [0. 0.]\n",
      "    [0. 0.]]\n",
      "\n",
      "   [[0. 0.]\n",
      "    [0. 0.]\n",
      "    [0. 0.]]\n",
      "\n",
      "   [[0. 0.]\n",
      "    [0. 0.]\n",
      "    [0. 0.]]\n",
      "\n",
      "   [[0. 0.]\n",
      "    [0. 0.]\n",
      "    [0. 0.]]]]]\n"
     ]
    }
   ],
   "source": [
    "print(q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPLORE_RATE_MIN = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE_MIN = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explore_rate(t):\n",
    "    # decay the exploration rate but not too fast, we want to explore less as we're more sure of getting the balance right\n",
    "    return max(EXPLORE_RATE_MIN, min(1, 1.0 - math.log10((t + 1) / 25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learning_rate(t):\n",
    "    # start with a larger learning rate and decay it slowly\n",
    "    return max(LEARNING_RATE_MIN, min(0.5, 1.0 - math.log10((t + 1) / 25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, explore_rate):\n",
    "    # explore the sample space at random based on the explore_rate\n",
    "    if random.random() < explore_rate:\n",
    "        action = env.action_space.sample()\n",
    "    # perform the action that gets us to the state with the highest Q-value\n",
    "    else:\n",
    "        action = np.argmax(q_table[state])\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_bucket(state):\n",
    "    bucket_indices = []\n",
    "    \n",
    "    for i in range(len(state)):\n",
    "        # if state is beyond the lower bounds, set it to the smallest bucket\n",
    "        if state[i] <= STATE_BOUNDS[i][0]:\n",
    "            bucket_index = 0\n",
    "        # if state is beyond the upper bounds, cap it to the largest bucket\n",
    "        elif state[i] >= STATE_BOUNDS[i][1]:\n",
    "            bucket_index = NUM_BUCKETS[i] - 1\n",
    "        else:\n",
    "            bound_width = STATE_BOUNDS[i][1] - STATE_BOUNDS[i][0]\n",
    "            \n",
    "            # use the bound width and the number of buckets to calculate which discrete bucket our continuous value falls in\n",
    "            offset = (NUM_BUCKETS[i] - 1) * STATE_BOUNDS[i][0] / bound_width\n",
    "            scaling = (NUM_BUCKETS[i] -1) / bound_width\n",
    "            \n",
    "            bucket_index = int(round(scaling * state[i] - offset))\n",
    "        \n",
    "        bucket_indices.append(bucket_index)\n",
    "    \n",
    "    return tuple(bucket_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate():\n",
    "    learning_rate = get_learning_rate(0)\n",
    "    explore_rate = get_explore_rate(0)\n",
    "    \n",
    "    discount_factor = 0.99\n",
    "    # how long has the pole balanced on the cart? 200 times instances makes one streak\n",
    "    num_streaks = 0\n",
    "    \n",
    "    for episode in range(1000):\n",
    "        observ = env.reset()\n",
    "        \n",
    "        state_0 = state_to_bucket(observ)\n",
    "        \n",
    "        for t in range(250):\n",
    "            \n",
    "            env.render()\n",
    "            \n",
    "            action = select_action(state_0, explore_rate)\n",
    "            \n",
    "            observ, reward, done, _ = env.step(action)\n",
    "            \n",
    "            state = state_to_bucket(observ)\n",
    "            \n",
    "            best_q = np.amax(q_table[state])\n",
    "            \n",
    "            # Q[s, a] = Q[s, a] + alpha * (R[s, a] + gamma * Max[Q(s', A)] - Q[s, a])\n",
    "            q_table[state_0 + (action,)] += learning_rate * (reward + discount_factor * (best_q) - q_table[state_0 + (action,)])\n",
    "            \n",
    "            state_0 = state\n",
    "            '''\n",
    "            print(\"\\Episode = %d\" % episode)\n",
    "            print(\"t = %d\" % t)\n",
    "            print(\"Action %d\" % action)\n",
    "            print(\"State %s\" % str(state))\n",
    "            print(\"Reward %f\" % reward)\n",
    "            print(\"Best Q %f\" % best_q)\n",
    "            print(\"Explore rate: %f\" % explore_rate)\n",
    "            print(\"Learning rate: %f\" % learning_rate)\n",
    "            print(\"Streaks: %d\" % num_streaks)\n",
    "            \n",
    "            print(\"\")\n",
    "            '''\n",
    "            \n",
    "            if done:\n",
    "                # print(\"Episode %d finished after %f time steps\" % (episode, t))\n",
    "                \n",
    "                if(t >= 199):\n",
    "                    num_streaks += 1\n",
    "                else:\n",
    "                    num_streaks = 0\n",
    "                break\n",
    "            \n",
    "            if num_streaks > 120:\n",
    "                break\n",
    "            \n",
    "            explore_rate = get_explore_rate(episode)\n",
    "            learning_rate = get_learning_rate(episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]]\n",
      "\n",
      "   [[75.6347248  72.01311701]\n",
      "    [61.91321938 77.25345304]\n",
      "    [19.54764926  0.        ]]\n",
      "\n",
      "   [[99.95313656 99.47635972]\n",
      "    [99.96840756 99.89861471]\n",
      "    [99.75726939 99.95456561]]\n",
      "\n",
      "   [[99.95466042 99.79294757]\n",
      "    [99.89639805 99.96873941]\n",
      "    [99.34346476 99.9534751 ]]\n",
      "\n",
      "   [[62.46445062 81.64068294]\n",
      "    [91.22575092 89.73081802]\n",
      "    [91.61159149 91.11241394]]\n",
      "\n",
      "   [[ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]]]]]\n"
     ]
    }
   ],
   "source": [
    "print(q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
